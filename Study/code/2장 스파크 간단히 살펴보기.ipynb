{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n",
    "# spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.shuffle.partitions', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+-------------------+--------------------+--------+------+---------+--------------------+\n",
      "|          event_time|event_type|product_id|        category_id|       category_code|   brand| price|  user_id|        user_session|\n",
      "+--------------------+----------+----------+-------------------+--------------------+--------+------+---------+--------------------+\n",
      "|2019-11-01 00:00:...|      view|   1003461|2053013555631882655|electronics.smart...|  xiaomi|489.07|520088904|4d3b30da-a5e4-49d...|\n",
      "|2019-11-01 00:00:...|      view|   5000088|2053013566100866035|appliances.sewing...|  janome|293.65|530496790|8e5f4f83-366c-4f7...|\n",
      "|2019-11-01 00:00:...|      view|  17302664|2053013553853497655|                null|   creed| 28.31|561587266|755422e7-9040-477...|\n",
      "|2019-11-01 00:00:...|      view|   3601530|2053013563810775923|appliances.kitche...|      lg|712.87|518085591|3bfb58cd-7892-48c...|\n",
      "|2019-11-01 00:00:...|      view|   1004775|2053013555631882655|electronics.smart...|  xiaomi|183.27|558856683|313628f1-68b8-460...|\n",
      "|2019-11-01 00:00:...|      view|   1306894|2053013558920217191|  computers.notebook|      hp|360.09|520772685|816a59f3-f5ae-4cc...|\n",
      "|2019-11-01 00:00:...|      view|   1306421|2053013558920217191|  computers.notebook|      hp|514.56|514028527|df8184cc-3694-454...|\n",
      "|2019-11-01 00:00:...|      view|  15900065|2053013558190408249|                null| rondell| 30.86|518574284|5e6ef132-4d7c-473...|\n",
      "|2019-11-01 00:00:...|      view|  12708937|2053013553559896355|                null|michelin| 72.72|532364121|0a899268-31eb-46d...|\n",
      "|2019-11-01 00:00:...|      view|   1004258|2053013555631882655|electronics.smart...|   apple|732.07|532647354|d2d3d2c6-631d-489...|\n",
      "+--------------------+----------+----------+-------------------+--------------------+--------+------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)\n",
    "df.columns\n",
    "df.dtypes\n",
    "temp = df.sample(False, 0.01, 333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.option(\"header\",True).|csv(\"./rawdata/2019-Nov.csv\")\n",
    "flightData2015 = spark\\\n",
    "    .read\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option('header', 'true')\\\n",
    "    .csv('../data/flight-data/csv/2015-summary.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=62)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Sort [count#40 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(count#40 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#51]\n",
      "   +- FileScan csv [DEST_COUNTRY_NAME#38,ORIGIN_COUNTRY_NAME#39,count#40] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/c:/Users/PC/OneDrive/Project/eCommerce_behavior_data_pipline/rawdata/csv/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.sort('count').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n",
       " Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015.sort('count').take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightData2015.createOrReplaceTempView(\"flight_data_2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlWay = spark.sql('''\n",
    "SELECT DEST_COUNTRY_NAME, count(1)\n",
    "FROM flight_data_2015\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrameWay = flightData2015\\\n",
    "  .groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    "  .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[DEST_COUNTRY_NAME#38], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(DEST_COUNTRY_NAME#38, 5), ENSURE_REQUIREMENTS, [id=#83]\n",
      "   +- *(1) HashAggregate(keys=[DEST_COUNTRY_NAME#38], functions=[partial_count(1)])\n",
      "      +- FileScan csv [DEST_COUNTRY_NAME#38] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/c:/Users/PC/OneDrive/Project/eCommerce_behavior_data_pipline/rawdata/csv/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[DEST_COUNTRY_NAME#38], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(DEST_COUNTRY_NAME#38, 5), ENSURE_REQUIREMENTS, [id=#102]\n",
      "   +- *(1) HashAggregate(keys=[DEST_COUNTRY_NAME#38], functions=[partial_count(1)])\n",
      "      +- FileScan csv [DEST_COUNTRY_NAME#38] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/c:/Users/PC/OneDrive/Project/eCommerce_behavior_data_pipline/rawdata/csv/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataFrameWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(count)=370002)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "\n",
    "flightData2015.select(max(\"count\")).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|destination_total|\n",
      "+-----------------+-----------------+\n",
      "|    United States|           411352|\n",
      "|           Canada|             8399|\n",
      "|           Mexico|             7140|\n",
      "|   United Kingdom|             2025|\n",
      "|            Japan|             1548|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxSql = spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, sum(count) as destination_total\n",
    "FROM flight_data_2015\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "ORDER BY sum(count) DESC\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "maxSql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|destination_total|\n",
      "+-----------------+-----------------+\n",
      "|    United States|           411352|\n",
      "|           Canada|             8399|\n",
      "|           Mexico|             7140|\n",
      "|   United Kingdom|             2025|\n",
      "|            Japan|             1548|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "flightData2015\\\n",
    "    .groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    "    .sum(\"count\")\\\n",
    "    .withColumnRenamed(\"sum(count)\", \"destination_total\")\\\n",
    "    .sort(desc(\"destination_total\"))\\\n",
    "    .limit(5)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "TakeOrderedAndProject(limit=5, orderBy=[destination_total#123L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#38,destination_total#123L])\n",
      "+- *(2) HashAggregate(keys=[DEST_COUNTRY_NAME#38], functions=[sum(cast(count#40 as bigint))])\n",
      "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#38, 5), ENSURE_REQUIREMENTS, [id=#210]\n",
      "      +- *(1) HashAggregate(keys=[DEST_COUNTRY_NAME#38], functions=[partial_sum(cast(count#40 as bigint))])\n",
      "         +- FileScan csv [DEST_COUNTRY_NAME#38,count#40] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/c:/Users/PC/OneDrive/Project/eCommerce_behavior_data_pipline/rawdata/csv/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,count:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015\\\n",
    "    .groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    "    .sum(\"count\")\\\n",
    "    .withColumnRenamed(\"sum(count)\", \"destination_total\")\\\n",
    "    .sort(desc(\"destination_total\"))\\\n",
    "    .limit(5)\\\n",
    "    .explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbce7473b076ec6af466c7b104bc5c4e2d4820e7cea15c4b4b344326b50eab45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('eCommerce')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
